"""
review_bridge.py - å®Œå…¨ä¿®æ­£ç‰ˆ
å°† AI-Scientist ç”Ÿæˆçš„ PDF è®ºæ–‡è½¬æ¢ä¸º Markdown å¹¶è°ƒç”¨ OpenReviewer ç”Ÿæˆè¯„å®¡
"""

import argparse
import sys
from pathlib import Path

# é€‚é…ç›®å½•ç»“æ„ï¼šai-scientist/AI-Scientist/tools/ å’Œ ai-scientist/openreviewer/
project_root = Path(__file__).parent.parent.parent
openreviewer_path = project_root / 'openreviewer'

print(f"ğŸ” è·¯å¾„è°ƒè¯•:")
print(f"   å½“å‰è„šæœ¬: {Path(__file__)}")
print(f"   é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"   OpenReviewer è·¯å¾„: {openreviewer_path}")
print(f"   OpenReviewer å­˜åœ¨: {openreviewer_path.exists()}\n")

sys.path.insert(0, str(openreviewer_path))

try:
    from app import generate
    print("âœ… æˆåŠŸå¯¼å…¥ OpenReviewer\n")
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ openreviewer.app: {e}")
    print(f"è¯·ç¡®ä¿ openreviewer ç›®å½•åœ¨: {openreviewer_path}")
    sys.exit(1)


def pdf_to_markdown(pdf_path: str) -> str:
    """ä½¿ç”¨ PyMuPDF æå– PDF æ–‡æœ¬"""
    try:
        import fitz  # PyMuPDF
    except ImportError:
        print("âŒ PyMuPDF æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install PyMuPDF")
        sys.exit(1)
    
    print(f"ğŸ“„ æå– PDF æ–‡æœ¬: {pdf_path}")
    
    doc = fitz.open(pdf_path)
    page_count = len(doc)  # â† åœ¨å…³é—­å‰ä¿å­˜é¡µæ•°
    markdown_text = ""
    
    for page_num in range(page_count):
        page = doc[page_num]
        text = page.get_text()
        markdown_text += text + "\n\n"
    
    doc.close()
    
    # åœ¨å…³é—­åä½¿ç”¨ä¿å­˜çš„ page_count
    print(f"âœ… æå–å®Œæˆ: {page_count} é¡µï¼Œå…± {len(markdown_text)} å­—ç¬¦")
    return markdown_text.strip()


def run_openreviewer(text_md: str, show_progress: bool = False) -> str:
    """è°ƒç”¨ OpenReviewer ç”Ÿæˆè¯„å®¡æ„è§"""
    
    REVIEW_TEMPLATE = """## Summary
Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary.

## Novelty
Please assign the paper a numerical rating on the following scale to indicate the novelty and originality of the work. Consider whether the paper presents new ideas, methods, or perspectives that have not been explored before. Choose from the following:
4: excellent - Highly original work with groundbreaking ideas or completely novel approaches
3: good - Significant new contributions with clear advances over existing work
2: fair - Some new elements but largely incremental improvements or combinations of existing ideas
1: poor - Little to no novelty, mostly reproducing existing work or trivial variations

## Novelty Explanation
IMPORTANT: Focus ONLY on novelty aspects. DO NOT discuss soundness, presentation, or general contribution here.
Please provide specific justification for your novelty score by addressing:
- What specific new concepts, methods, or approaches does this paper introduce?
- How do these differ from existing work in the field? Cite specific prior work for comparison.
- Are the differences substantial or incremental?
- Is this addressing a problem in a genuinely new way, or applying known methods to a new domain?
DO NOT repeat content from other sections. DO NOT discuss writing quality, experimental rigor, or implementation details here.

## Soundness
Please assign the paper a numerical rating on the following scale to indicate the soundness of the technical claims, experimental and research methodology and on whether the central claims of the paper are adequately supported with evidence. Choose from the following:
4: excellent
3: good
2: fair
1: poor

## Soundness Explanation
IMPORTANT: Focus ONLY on technical correctness and methodological rigor. DO NOT discuss novelty or writing quality here.
Please provide specific reasons for your soundness score by addressing:
- Are the technical claims mathematically/logically correct?
- Is the experimental methodology rigorous and appropriate?
- Are the experiments sufficient to support the claims?
- Are there any methodological flaws or missing controls?
- Is the statistical analysis (if any) appropriate and correctly executed?
DO NOT repeat content from other sections. DO NOT discuss the novelty of the approach or presentation quality here.

## Presentation
Please assign the paper a numerical rating on the following scale to indicate the quality of the presentation. This should take into account the writing style and clarity, as well as contextualization relative to prior work. Choose from the following:
4: excellent
3: good
2: fair
1: poor

## Presentation Explanation
IMPORTANT: Focus ONLY on writing quality, clarity, and organization. DO NOT discuss technical merit or novelty here.
Please explain your presentation score by addressing:
- Is the paper well-organized and easy to follow?
- Are the main ideas clearly explained?
- Are figures, tables, and visualizations effective and well-designed?
- Is the related work section comprehensive and fair?
- Are mathematical notations consistent and clear?
- Is the language precise and grammatically correct?
DO NOT repeat content from other sections. DO NOT discuss the novelty of ideas or soundness of methods here.

## Contribution
Please assign the paper a numerical rating on the following scale to indicate the quality of the overall contribution this paper makes to the research area being studied. Are the questions being asked important? Does the paper bring a significant originality of ideas and/or execution? Are the results valuable to share with the broader ICLR community? Choose from the following:
4: excellent
3: good
2: fair
1: poor

## Contribution Explanation
IMPORTANT: Focus on the OVERALL IMPACT and SIGNIFICANCE to the field. This is different from novelty.
Please justify your contribution score by explaining:
- Why is this work important for the field?
- What practical or theoretical impact could this have?
- Who would benefit from this work and how?
- Does this open new research directions or close important gaps?
- How significant are the improvements over baselines (if applicable)?
Consider both immediate utility and long-term impact. DO NOT simply repeat the novelty assessment here.

## Strengths
List the main strengths of the paper. Be specific and provide evidence. Each strength should be a separate bullet point. Focus on what the paper does well across all dimensions (novelty, soundness, presentation, contribution). Avoid generic statements.

## Weaknesses
List the main weaknesses of the paper. Be specific, constructive, and actionable. Each weakness should be a separate bullet point with suggestions for improvement where possible. Focus on significant issues that affect the paper's validity or impact.

## Questions
List specific questions for the authors that could clarify ambiguities or address concerns. Number each question. These should be questions where the answer could potentially change your assessment of the paper.

## Flag For Ethics Review
If there are ethical issues with this paper, please flag the paper for an ethics review and select area of expertise that would be most useful for the ethics reviewer to have. Please select all that apply. Choose from the following:
No ethics review needed.
Yes, Discrimination / bias / fairness concerns
Yes, Privacy, security and safety
Yes, Legal compliance (e.g., GDPR, copyright, terms of use)
Yes, Potentially harmful insights, methodologies and applications
Yes, Responsible research practice (e.g., human subjects, data release)
Yes, Research integrity issues (e.g., plagiarism, dual submission)
Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)
Yes, Other reasons (please specify below)

## Details Of Ethics Concerns
Please provide details of your concerns. If no ethics review is needed, write "N/A".

## Rating
Please provide an "overall score" for this submission. Choose from the following:
1: strong reject
3: reject, not good enough
5: marginally below the acceptance threshold
6: marginally above the acceptance threshold
8: accept, good paper
10: strong accept, should be highlighted at the conference

## Overall Justification
Provide a comprehensive justification for your overall rating that:
- Synthesizes the assessments from all dimensions (novelty, soundness, presentation, contribution)
- Explains how you weighted different aspects in arriving at your final score
- Clearly states whether the strengths outweigh the weaknesses or vice versa
- Indicates what would need to change for a different rating
This should be a holistic assessment, not a repetition of individual sections.
"""
    
    print("ğŸ” OpenReviewer æ­£åœ¨ç”Ÿæˆè¯„å®¡æ„è§...")
    if show_progress:
        print("   (å®æ—¶æ˜¾ç¤ºè¿›åº¦)\n")
    
    try:
        output = generate(text_md, review_template=REVIEW_TEMPLATE)
        
        # å¸¦è¿›åº¦æ˜¾ç¤º
        if show_progress:
            collected = []
            last_length = 0
            
            if hasattr(output, "__iter__") and not isinstance(output, (str, dict)):
                for item in output:
                    if isinstance(item, str):
                        collected.append(item)
                        current_text = "\n".join(collected)
                        new_text = current_text[last_length:]
                        if new_text:
                            print(new_text, end='', flush=True)
                            last_length = len(current_text)
                
                print("\n")
                return "\n".join(collected)
        
        # ä¸æ˜¾ç¤ºè¿›åº¦
        if isinstance(output, str):
            return output
        
        if hasattr(output, "__iter__") and not isinstance(output, (str, dict)):
            collected = []
            for item in output:
                if isinstance(item, str):
                    collected.append(item)
            return "\n".join(collected)
        
        if isinstance(output, dict):
            md = ""
            for k, v in output.items():
                md += f"## {k}\n{v}\n\n"
            return md
        
        return str(output)
    
    except Exception as e:
        print(f"âŒ OpenReviewer ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


def main():
    parser = argparse.ArgumentParser(
        description="å°† AI-Scientist ç”Ÿæˆçš„ PDF è®ºæ–‡è‡ªåŠ¨è¯„å®¡"
    )
    parser.add_argument("--pdf", required=True, help="è¾“å…¥çš„ PDF æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--out_dir", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--model", default="gpt-4o", help="æ¨¡å‹åç§°ï¼ˆä¿ç•™å‚æ•°ï¼‰")
    parser.add_argument("--show-progress", action="store_true", help="æ˜¾ç¤ºç”Ÿæˆè¿›åº¦")
    args = parser.parse_args()
    
    pdf_path = Path(args.pdf)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    if not pdf_path.exists():
        print(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        sys.exit(1)
    
    print("\n" + "="*70)
    print("ğŸš€ å¼€å§‹å¤„ç†è®ºæ–‡è¯„å®¡")
    print("="*70)
    print(f"ğŸ“„ PDF: {pdf_path}")
    print(f"ğŸ“ è¾“å‡º: {out_dir}")
    print("="*70 + "\n")
    
    # Step 1: PDF â†’ Markdown
    markdown_text = pdf_to_markdown(str(pdf_path))
    md_path = out_dir / "paper.md"
    md_path.write_text(markdown_text, encoding="utf-8")
    print(f"âœ… Markdown: {md_path}\n")
    
    # Step 2: ç”Ÿæˆè¯„å®¡
    review_md = run_openreviewer(markdown_text, show_progress=args.show_progress)
    review_path = out_dir / "review.md"
    review_path.write_text(review_md, encoding="utf-8")
    print(f"âœ… è¯„å®¡: {review_path}\n")
    
    print("="*70)
    print("ğŸ‰ å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    main()